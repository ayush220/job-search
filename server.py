#!/usr/bin/env python
"""
Simple HTTP server to handle job search requests from the web interface.
"""
import http.server
import socketserver
import json
import subprocess
import sys
import os
import webbrowser
import threading
import pandas as pd
from urllib.parse import parse_qs, urlparse

# Get port from environment variable or use default
import os
PORT = int(os.environ.get('PORT', 10000))

class JobSearchHandler(http.server.SimpleHTTPRequestHandler):
    def do_OPTIONS(self):
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()
    def do_POST(self):
        if self.path == '/run-job-search':
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            # Get search parameters
            title = data.get('title', 'software engineer,backend')
            location = data.get('location', 'all')
            
            # Build command to run job scraper
            cmd = [sys.executable, 'job_scraper.py']
            if title:
                cmd.extend(['--title', title])
            if location and location.lower() != 'all':
                cmd.extend(['--location', location])
            
            # Run the job scraper
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                output = result.stdout
                
                # Read the CSV file generated by the job scraper
                if os.path.exists('jobs.csv'):
                    try:
                        df = pd.read_csv('jobs.csv')
                        # Convert NaN values to None (which becomes null in JSON)
                        df = df.where(pd.notnull(df), None)
                        jobs = df.to_dict('records')
                        
                        # Send the jobs as JSON
                        self.send_response(200)
                        self.send_header('Content-type', 'application/json')
                        self.end_headers()
                        self.wfile.write(json.dumps({
                            'success': True,
                            'output': output,
                            'jobs': jobs
                        }).encode())
                    except Exception as e:
                        self.send_response(500)
                        self.send_header('Content-type', 'application/json')
                        self.end_headers()
                        self.wfile.write(json.dumps({
                            'success': False,
                            'output': output,
                            'error': f'Error processing CSV: {str(e)}'
                        }).encode())
                else:
                    self.send_response(404)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    self.wfile.write(json.dumps({
                        'success': False,
                        'output': output,
                        'error': 'No jobs found'
                    }).encode())
            except subprocess.CalledProcessError as e:
                self.send_response(500)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps({
                    'success': False,
                    'output': e.stdout if e.stdout else '',
                    'error': e.stderr if e.stderr else 'Error running job scraper'
                }).encode())
        else:
            self.send_response(404)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({
                'success': False,
                'error': 'Invalid endpoint'
            }).encode())

def open_browser(port):
    """Open browser after a short delay"""
    import time
    time.sleep(1)
    webbrowser.open(f'http://localhost:{port}')

def run_server():
    """Run the HTTP server"""
    global PORT
    
    # Change to the directory containing this script
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    
    try:
        # Create server
        with socketserver.TCPServer(("0.0.0.0", PORT), JobSearchHandler) as httpd:
            print(f"Serving at port {PORT}")
            print(f"Open http://localhost:{PORT}/web_interface.html in your browser")
            httpd.serve_forever()
    except OSError as e:
        if "Address already in use" in str(e):
            print(f"Port {PORT} is already in use. Please try a different port.")
        else:
            print(f"Error starting server: {str(e)}")

if __name__ == "__main__":
    # Run the server (which will also open the browser)
    run_server()
